# ECSE211-Mouse-Odometry-Experiment
Preliminary faffing about to see if it's possible to use a mouse to track relative ground movement as EV3 LeJOS as a platform.

## Honourable Mentions
Professor Frank Ferrie, for providing this interesting idea within the first couple of weeks of the course.

Ryan Au, who gave excellent analysis on the feasibility of using a mouse far better than I could and gave me several links to things to look at to attempt this idea.

## BACKGROUND
For the McGill ECSE211 course we are required to build a full robot system with EV3 Lego Mindstorms as our hardware platform and Java running on LeJOS as out software platform. One of the tasks our robots must accomplish is odometry. Thus far, we have relied upon reading in the tachometers of our robot's left and right motors which are directly attached to the wheels maneuvering the robot. Unfortunately, this configurations suffers from two problems: Firstly, the two motors do not behave physically identically which means there is effective "drift" when the robot is attempting straight lines or even rotations about a centre wherein one of the motors will start first; and secondly, the use of the motor's tachometers almost makes the system's control scheme an open-loop control system as that the intended motor movements have obtained us the desired result in displacement (ie, if the robot's wheel(s) slip(s), the robot will have no feedback loop for realizing an error occured).

The solution to the abovementioned problem is therefore to make use of a sensor to validate the robot's movement or localize it. Thus far, we have been provided three additional sensors: an Ultrasonic sensor, a Light sensor, and a Gyroscopic sensor. 
The ultrasonic sensor has an error range of 1 cm but works somewhat well. It is most accurate when pointed directly perpendicularly to a surface and worsens the further off its orientation is from this ideal orientation. The maximum range of the Ultrasonic Sensor is about two and a half metres. 
The Light sensor is noisy, but the noise is like a gaussian distribution with a bit of a negative bias. With a differential filter this system works effectively assuming the robot is working on a flat surface with regular intervals of lines on which the robot can relocalize. Note that the light sensor is unable to complete initial localization as it cannot find direction in a play field; it must be accompanied by an ultrasonic sensor to detect the two nearest walls or initial orientation data. Finally, the gyroscopic sensor is, well, a gyroscope. It keeps track of orientation with an error range of 1 degree. 
The gyroscope is useless without external systems. However, given the current tachometer-based odometry system we have thus far implemented in our ECSE 211 course (as of February 14th 2020), it does offer one advantage: in the case of a robot having a tendency to drift irregardless of having the same commands sent to both left and right motors, the gyroscope can notice that the robot is drifting off its straight path whereas the current tachometer system cannot (the tachometers have thus far always indicated the robots are traveling in perfectly straight lines even if they emperically have not been). 

The above three sensors have their advantages and disadvantages, but hardly constitute a high-resolution solution to our odometry problems. But perhaps there is a third alternative. After discussion with Professor Frank Ferrie and a fellow student Ryan Au, it seems that it may very well be possible to connect a USB mouse to the EV3 Mindstorms brick and obtain mouse data. How would a mouse be useful? Mice provide two dimensional movement data: displacement on its X axis, and displacement on its Y axis. Aligning the Y axis to the robot's front-and-back pointed axis, aligning the mouse to be of equal distance from the left and right wheels, and offsetting the mouse to be of measured distance forward of the robot's centre of rotation (centre about which the robot does not change when both motors are at equal speeds but different direction) the mouse's y axis displacement data can be mapped to the robot's foward and backward movement while the mouse's x axis displacement data can be mapped to the robot's leftward and rightward rotation. Combined with mice having advertised resolutions in the hundreds or thousands dots per inch, mice may provide a high-resolution sensor solution to our odometry issue.

Interestingly, after discussion with Ryan Au who has previously spliced a mouse to be connected to a Lego Mindstorms system through an I2C connection, it seems that mice may not provide very good quality data. Sure, the data may be high in throughput; however, there may be accuracy issues originating from how mice manufacturers do not need to make mice that measure the displacement of their mice on surfaces perfectly due to the presence of a human user who can compensate for mice inaccuracies almost automatically. In particular, laser mice may not provide very good data. However, the use of ball-effector mice does not appear to have been explored. In other words, it might work.

## OBJECTIVE (2020-02-14)
I would like to explore a few things. First I want to see if I can get displacement data from mice through a Java program I write and run on Windows. Testing the program on Windows first makes figuring out the feasibility of writing, effectively, a Java mouse driver faster. Ryan Au analyzed and provided the groundwork needed for getting this started. As such, I have attached a copy of the email he sent me after an exchange detailing where to start.
